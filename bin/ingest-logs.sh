#!/bin/bash
set -euo pipefail

# =============================================================================
# Forgeloop Log Ingestion
# =============================================================================
# Analyzes logs/errors via LLM and appends a formatted request to REQUESTS.md.
# Supports best-effort dedupe using both a content hash and an issue signature.
#
# Usage:
#   ./forgeloop/bin/ingest-logs.sh --file /var/log/myapp.log
#   ./forgeloop/bin/ingest-logs.sh --cmd "journalctl -u myapp -n 400 --no-pager"
#   some_command | ./forgeloop/bin/ingest-logs.sh --stdin
#
# Options:
#   --file <path>        Path to a log file (absolute or relative to repo root)
#   --cmd <command>      Command to run to fetch logs (captured from stdout+stderr)
#   --stdin              Read logs from stdin
#   --logs-dir <dir>     Directory containing logs (default: logs)
#   --latest             Use the most recently modified file in --logs-dir (filtered by --glob)
#   --glob <pattern>     Filename pattern for --latest selection (default: *.log)
#   --tail <lines>       Number of lines to include (default: 400)
#   --max-chars <n>      Max characters sent to the LLM (default: 60000)
#   --source <label>     Human label recorded in REQUESTS.md (default: auto)
#   --requests <path>    Path to REQUESTS.md (default: from config)
#   --mode <mode>        Output mode: request (default) or plan-work
#   --dry-run            Print what would be appended without writing
#   --json-out <path>    Save the raw LLM JSON response
#   --force              Skip dedupe checks, ingest even if already processed
#   --no-redact          Disable redaction (NOT recommended; logs often contain secrets/PII)
# =============================================================================

# Resolve repo directory and load libraries
REPO_DIR="$(cd "$(dirname "$0")/../.." && pwd)"
FORGELOOP_DIR="$REPO_DIR/forgeloop"
if [[ ! -f "$FORGELOOP_DIR/lib/core.sh" ]]; then
    FORGELOOP_DIR="$REPO_DIR"
fi
source "$FORGELOOP_DIR/config.sh" 2>/dev/null || true
source "$FORGELOOP_DIR/lib/core.sh"
source "$FORGELOOP_DIR/lib/llm.sh"

forgeloop_core__require_cmd "jq"

# Setup runtime directories
RUNTIME_DIR=$(forgeloop_core__ensure_runtime_dirs "$REPO_DIR")
LOG_FILE="${FORGELOOP_INGEST_LOGS_LOG_FILE:-$RUNTIME_DIR/logs/ingest-logs.log}"

# Defaults
LOGS_DIR="${FORGELOOP_LOGS_DIR:-logs}"
REQUESTS_FILE="${FORGELOOP_REQUESTS_FILE:-REQUESTS.md}"
MODE="request"
DRY_RUN=false
FORCE=false
REDACT=true

LOG_FILE_PATH=""
LOGS_CMD=""
READ_STDIN=false
LATEST=false
GLOB="*.log"
TAIL_LINES="${FORGELOOP_INGEST_LOGS_TAIL:-400}"
MAX_CHARS="${FORGELOOP_INGEST_LOGS_MAX_CHARS:-60000}"
SOURCE_LABEL=""
JSON_OUT=""

log() { forgeloop_core__log "$1" "$LOG_FILE"; }
notify() { forgeloop_core__notify "$REPO_DIR" "$@"; }

usage() {
    cat <<'USAGE'
Forgeloop Log Ingestion

Analyzes logs/errors via an LLM and appends a formatted request to REQUESTS.md.

Usage:
  ./forgeloop/bin/ingest-logs.sh --file /var/log/myapp.log
  ./forgeloop/bin/ingest-logs.sh --cmd "journalctl -u myapp -n 400 --no-pager"
  some_command | ./forgeloop/bin/ingest-logs.sh --stdin

Options:
  --file <path>        Path to a log file (absolute or relative to repo root)
  --cmd <command>      Command to run to fetch logs (captured from stdout+stderr)
  --stdin              Read logs from stdin
  --logs-dir <dir>     Directory containing logs (default: logs)
  --latest             Use the most recently modified file in --logs-dir (filtered by --glob)
  --glob <pattern>     Filename pattern for --latest selection (default: *.log)
  --tail <lines>       Number of lines to include (default: 400)
  --max-chars <n>      Max characters sent to the LLM (default: 60000)
  --source <label>     Human label recorded in REQUESTS.md (default: auto)
  --requests <path>    Path to REQUESTS.md (default: from config)
  --mode <mode>        Output mode: request (default) or plan-work
  --dry-run            Print what would be appended without writing
  --json-out <path>    Save the raw LLM JSON response
  --force              Skip dedupe checks, ingest even if already processed
  --no-redact          Disable redaction (NOT recommended; logs often contain secrets/PII)
USAGE
}

# =============================================================================
# Argument Parsing
# =============================================================================

while [[ $# -gt 0 ]]; do
    case "$1" in
        --file)
            LOG_FILE_PATH="$2"
            shift 2
            ;;
        --cmd)
            LOGS_CMD="$2"
            shift 2
            ;;
        --stdin)
            READ_STDIN=true
            shift
            ;;
        --logs-dir)
            LOGS_DIR="$2"
            shift 2
            ;;
        --latest)
            LATEST=true
            shift
            ;;
        --glob)
            GLOB="$2"
            shift 2
            ;;
        --tail)
            TAIL_LINES="$2"
            shift 2
            ;;
        --max-chars)
            MAX_CHARS="$2"
            shift 2
            ;;
        --source)
            SOURCE_LABEL="$2"
            shift 2
            ;;
        --requests)
            REQUESTS_FILE="$2"
            shift 2
            ;;
        --mode)
            MODE="$2"
            shift 2
            ;;
        --dry-run)
            DRY_RUN=true
            shift
            ;;
        --force)
            FORCE=true
            shift
            ;;
        --json-out)
            JSON_OUT="$2"
            shift 2
            ;;
        --no-redact)
            REDACT=false
            shift
            ;;
        -h|--help)
            usage
            exit 0
            ;;
        *)
            echo "Unknown option: $1" >&2
            exit 1
            ;;
    esac
done

# =============================================================================
# Input Selection + Sampling
# =============================================================================

select_latest_log_file() {
    local dir="$REPO_DIR/$LOGS_DIR"
    if [[ ! -d "$dir" ]]; then
        echo "Error: Logs directory not found: $dir" >&2
        exit 1
    fi

    local latest
    latest=$(find "$dir" -maxdepth 1 -type f -name "$GLOB" -print0 2>/dev/null | \
        xargs -0 ls -t 2>/dev/null | head -1 || echo "")

    if [[ -z "$latest" ]]; then
        echo "Error: No log files matching '$GLOB' found in $dir" >&2
        exit 1
    fi

    echo "$latest"
}

resolve_file_path() {
    local p="$1"
    if [[ "$p" != /* ]]; then
        p="$REPO_DIR/$p"
    fi
    if [[ ! -f "$p" ]]; then
        echo "Error: Log file not found: $p" >&2
        exit 1
    fi
    echo "$p"
}

validate_inputs() {
    local sources=0
    [[ -n "$LOG_FILE_PATH" ]] && sources=$((sources + 1))
    [[ -n "$LOGS_CMD" ]] && sources=$((sources + 1))
    [[ "$READ_STDIN" == "true" ]] && sources=$((sources + 1))
    [[ "$LATEST" == "true" ]] && sources=$((sources + 1))

    # Convenience: if nothing specified but stdin is piped, read it.
    if [[ "$sources" -eq 0 ]] && [[ ! -t 0 ]]; then
        READ_STDIN=true
        sources=1
    fi

    if [[ "$sources" -eq 0 ]]; then
        echo "Error: Provide exactly one of --file, --cmd, --stdin, or --latest/--logs-dir." >&2
        exit 1
    fi
    if [[ "$sources" -gt 1 ]]; then
        echo "Error: Provide only one input source (--file, --cmd, --stdin, or --latest)." >&2
        exit 1
    fi
}

collect_cmd_output() {
    local cmd="$1"
    local out_file="$2"
    local exit_code
    set +e
    bash -lc "$cmd" >"$out_file" 2>&1
    exit_code=$?
    set -e
    echo "$exit_code"
}

redact_sensitive() {
    local in_file="$1"
    local out_file="$2"

    if [[ "$REDACT" != "true" ]]; then
        cp "$in_file" "$out_file"
        return 0
    fi

    # Best-effort redaction for common secrets. Keep this conservative to avoid destroying log signal.
    awk '
        BEGIN { in_key=0 }
        /-----BEGIN [A-Z ]*PRIVATE KEY-----/ { print "[REDACTED_PRIVATE_KEY_BLOCK]"; in_key=1; next }
        /-----END [A-Z ]*PRIVATE KEY-----/ { in_key=0; next }
        in_key==1 { next }
        { print }
    ' "$in_file" | sed -E \
        -e 's/AKIA[0-9A-Z]{16}/[REDACTED_AWS_KEY]/g' \
        -e 's/ghp_[A-Za-z0-9]{36,}/[REDACTED_GITHUB_TOKEN]/g' \
        -e 's/xox[baprs]-[0-9A-Za-z-]+/[REDACTED_SLACK_TOKEN]/g' \
        -e 's/((password|passwd|secret|api[_-]?key|token)[[:space:]]*[=:][[:space:]]*)[^[:space:]]+/\\1[REDACTED]/Ig' \
        > "$out_file"
}

sample_logs() {
    local raw_file="$1"
    local sampled_file="$2"
    tail -n "$TAIL_LINES" "$raw_file" > "$sampled_file"
}

truncate_chars() {
    local in_file="$1"
    local out_file="$2"
    head -c "$MAX_CHARS" "$in_file" > "$out_file"
}

# =============================================================================
# Dedupe
# =============================================================================

get_content_hash() {
    local file="$1"
    forgeloop_core__hash_file "$file" | cut -c1-12
}

get_signature_hash() {
    local sig="$1"
    forgeloop_core__hash "$sig" | cut -c1-12
}

is_already_ingested() {
    local content_hash="$1"
    local signature_hash="$2"
    local requests_path="$REPO_DIR/$REQUESTS_FILE"

    if [[ ! -f "$requests_path" ]]; then
        return 1
    fi

    grep -q "Source: logs:$content_hash" "$requests_path" 2>/dev/null && return 0
    [[ -n "$signature_hash" ]] && grep -q "Signature: logsig:$signature_hash" "$requests_path" 2>/dev/null && return 0
    return 1
}

# =============================================================================
# LLM Analysis
# =============================================================================

analyze_logs() {
    local logs_file="$1"
    local source_label="$2"
    local redacted="$3"
    local cmd_exit_code="$4"
    local log_content
    log_content=$(cat "$logs_file")

    local prompt="You are analyzing runtime logs to identify the single most actionable engineering task.

CONSTRAINTS:
- Must be completable in a few hours of focused work
- Must be a clear, specific task (not vague)
- Prefer fixes over new features
- If logs are missing key context, propose the minimal next step to get it (do not ask for broad rewrites)
- Create a stable issue_signature: no timestamps, request IDs, UUIDs, user IDs, IPs, or other volatile identifiers

LOG_SOURCE: $source_label
TAIL_LINES: $TAIL_LINES
REDACTED: $redacted
CMD_EXIT_CODE: $cmd_exit_code

LOG_SNIPPET:
$log_content

Respond with ONLY a single-line JSON object (no markdown, no code fences):
{
  \"issue_signature\": \"stable short signature\",
  \"title\": \"Brief task title\",
  \"description\": \"2-3 sentences describing what needs to be done\",
  \"probable_root_cause\": \"Best guess based on the logs\",
  \"next_steps\": [\"2-4 short steps to confirm/reproduce or gather missing info\"],
  \"work_scope\": \"Single sentence scope for plan-work prompt\",
  \"acceptance_criteria\": [\"3-5 specific, verifiable criteria\"],
  \"priority\": \"high\",
  \"type\": \"fix\"
}"

    local result json_text
    result=$(echo "$prompt" | forgeloop_llm__exec "$REPO_DIR" "stdin" "plan" "" "$LOG_FILE" 2>&1)

    json_text=$(echo "$result" | grep -E '^\{' | head -1 || echo "")
    if [[ -z "$json_text" ]]; then
        json_text=$(echo "$result" | sed -n '/^{/,/^}/p' | head -50)
    fi

    if ! echo "$json_text" | jq . >/dev/null 2>&1; then
        echo "Error: Could not parse LLM response as JSON" >&2
        echo "Response: $result" >&2
        exit 1
    fi

    echo "$json_text"
}

# =============================================================================
# Output Formatting
# =============================================================================

format_request() {
    local json="$1"
    local content_hash="$2"
    local signature_hash="$3"
    local source_label="$4"
    local redacted="$5"
    local cmd_exit_code="$6"
    local timestamp
    timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

    local title description priority type root_cause
    title=$(echo "$json" | jq -r '.title // "Untitled"')
    description=$(echo "$json" | jq -r '.description // ""')
    priority=$(echo "$json" | jq -r '.priority // "medium"')
    type=$(echo "$json" | jq -r '.type // "task"')
    root_cause=$(echo "$json" | jq -r '.probable_root_cause // ""')

    local next_steps acceptance
    next_steps=$(echo "$json" | jq -r '.next_steps[]? // empty' | while read -r line; do
        echo "- $line"
    done)
    acceptance=$(echo "$json" | jq -r '.acceptance_criteria[]? // empty' | while read -r line; do
        echo "- $line"
    done)

    cat << EOF

## $title
- Priority: $priority
- Type: $type

$description

**Probable Root Cause:** $root_cause

### Next Steps
$next_steps

### Acceptance Criteria
$acceptance

---
Source: logs:$content_hash
Signature: logsig:$signature_hash
LogSource: $source_label
TailLines: $TAIL_LINES
Redacted: $redacted
CmdExitCode: $cmd_exit_code
CreatedAt: $timestamp
EOF
}

format_plan_work_scope() {
    local json="$1"
    echo "$json" | jq -r '.work_scope // .description // "Fix the top issue from the logs"'
}

# =============================================================================
# Main
# =============================================================================

main() {
    validate_inputs

    local tmp_raw tmp_sample tmp_redacted tmp_final
    tmp_raw=$(mktemp)
    tmp_sample=$(mktemp)
    tmp_redacted=$(mktemp)
    tmp_final=$(mktemp)
    trap 'rm -f "$tmp_raw" "$tmp_sample" "$tmp_redacted" "$tmp_final"' EXIT

    local source_label cmd_exit_code
    source_label="${SOURCE_LABEL:-auto}"
    cmd_exit_code="0"

    if [[ "$LATEST" == "true" ]]; then
        LOG_FILE_PATH=$(select_latest_log_file)
    fi

    if [[ -n "$LOG_FILE_PATH" ]]; then
        LOG_FILE_PATH=$(resolve_file_path "$LOG_FILE_PATH")
        source_label="${SOURCE_LABEL:-file:$LOG_FILE_PATH}"
        # Avoid reading the full file into memory/disk: sample directly.
        tail -n "$TAIL_LINES" "$LOG_FILE_PATH" > "$tmp_sample"
    elif [[ -n "$LOGS_CMD" ]]; then
        source_label="${SOURCE_LABEL:-cmd}"
        cmd_exit_code=$(collect_cmd_output "$LOGS_CMD" "$tmp_raw")
        if [[ ! -s "$tmp_raw" ]]; then
            echo "Error: Command produced no output: $LOGS_CMD" >&2
            exit 1
        fi
    else
        source_label="${SOURCE_LABEL:-stdin}"
        if [[ -t 0 ]]; then
            echo "Error: --stdin specified but no data on stdin" >&2
            exit 1
        fi
        cat > "$tmp_raw"
    fi

    if [[ -s "$tmp_raw" ]]; then
        sample_logs "$tmp_raw" "$tmp_sample"
    fi
    redact_sensitive "$tmp_sample" "$tmp_redacted"
    truncate_chars "$tmp_redacted" "$tmp_final"

    local redacted_flag
    if [[ "$REDACT" == "true" ]]; then redacted_flag="true"; else redacted_flag="false"; fi

    local content_hash
    content_hash=$(get_content_hash "$tmp_final")
    log "Logs content hash: $content_hash (source: $source_label)"

    # Analyze logs (LLM)
    log "Analyzing logs..."
    local analysis_json
    analysis_json=$(analyze_logs "$tmp_final" "$source_label" "$redacted_flag" "$cmd_exit_code")

    if [[ -n "$JSON_OUT" ]]; then
        echo "$analysis_json" > "$JSON_OUT"
        log "Saved analysis JSON to: $JSON_OUT"
    fi

    local issue_signature signature_hash
    issue_signature=$(echo "$analysis_json" | jq -r '.issue_signature // empty')
    if [[ -z "$issue_signature" ]] || [[ "$issue_signature" == "null" ]]; then
        issue_signature=$(echo "$analysis_json" | jq -r '.title // "unknown"')
    fi
    signature_hash=$(get_signature_hash "$issue_signature")

    if [[ "$FORCE" != "true" ]] && is_already_ingested "$content_hash" "$signature_hash"; then
        log "Already ingested (content:$content_hash signature:$signature_hash). Use --force to re-ingest."
        echo "Already ingested. Use --force to re-ingest."
        exit 0
    fi

    case "$MODE" in
        request)
            local formatted_request
            formatted_request=$(format_request "$analysis_json" "$content_hash" "$signature_hash" "$source_label" "$redacted_flag" "$cmd_exit_code")

            if [[ "$DRY_RUN" == "true" ]]; then
                echo "=== DRY RUN: Would append to $REQUESTS_FILE ==="
                echo "$formatted_request"
            else
                local requests_path="$REPO_DIR/$REQUESTS_FILE"
                echo "$formatted_request" >> "$requests_path"
                log "Appended request to $REQUESTS_FILE"
                notify "ðŸ“¥" "Logs Ingested" "Added new request from logs"

                if [[ "${FORGELOOP_INGEST_TRIGGER_REPLAN:-false}" == "true" ]]; then
                    echo "[REPLAN]" >> "$requests_path"
                    log "Added [REPLAN] trigger"
                fi

                echo "Request appended to $REQUESTS_FILE"
            fi
            ;;

        plan-work)
            local work_scope
            work_scope=$(format_plan_work_scope "$analysis_json")

            if [[ "$DRY_RUN" == "true" ]]; then
                echo "=== DRY RUN: Would run plan-work with scope ==="
                echo "$work_scope"
            else
                log "Running plan-work with scope: $work_scope"
                "$REPO_DIR/forgeloop/bin/loop.sh" plan-work "$work_scope" 1
            fi
            ;;

        *)
            echo "Unknown mode: $MODE" >&2
            exit 1
            ;;
    esac
}

main
